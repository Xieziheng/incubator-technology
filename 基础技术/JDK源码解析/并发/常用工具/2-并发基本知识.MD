### 1.串行OR并行
#### 1.1:阿姆达尔定律
一个程序（或者一个算法）可以按照是否可以被并行化分为下面两个部分：

1:可以被并行化的部分

2:不可以被并行化的部分

那么用公式来表示：
T = 串行执行的总时间
B = 不可以并行的总时间
T- B = 并行部分的总时间
从上面可以得出：

T = B + (T – B)

T- B 是可并行化的部分，以并行的方式执行可以提高程序的运行速度。可以提速多少取决于有多少线程或者多少个CPU来执行。线程或者CPU的个数我们记为N。可并行化部分被执行的最快时间可以通过下面的公式计算出来：

(T – B ) / N

或者通过这种方式

(1 / N) * (T – B)

根据阿姆达尔定律，当一个程序的可并行部分使用N个线程或CPU执行时，执行的总时间为：

T(N) = B + ( T – B ) / N

T(N)指的是在并行因子为N时的总执行时间。因此，T(1)就执行在并行因子为1时程序的总执行时间。使用T(1)代替T，阿姆达尔定律定律看起来像这样：

T(N) = B + (T(1) – B) / N

#### 1.2:并发编程
并发编程目的是让程序更快，多个线程执行任务，但一般来讲，并发编程会面临很多问题。比如上下文切换，死锁，以及受限于硬件和软件的资源限制问题（资源不限于内存，还有机器的总线，CPU等等）。


一般来讲，我们进行多线程操作的话线程数一定要考虑上下文切换，机器的总核数，是计算密集型还是io密集型。
#### 1.2.1：上下文切换
多线程执行在少数情况下并不一定比串行执行快。

可以试试累加操作。

当并发执行累加操作不超过100w的时候速度会比串行执行操作快。就是因为线程有创建和上下文切换的开销。

#### 1.2.2:常用工具
Lmbench测量上下文切换的时长

Vmstat测量上下文切换次数

vmstat命令基本可以确认，如果r高证明瓶颈在线程操作上，如果cs高证明在上下文切换上。

#### 1.2.3:引起上下文切换的原因

1. 当前执行任务的时间片用完之后, 系统CPU正常调度下一个任务

2. 当前执行任务碰到IO阻塞, 调度器将挂起此任务, 继续下一任务

3. 多个任务抢占锁资源, 当前任务没有抢到,被调度器挂起, 继续下一任务

4. 用户代码挂起当前任务, 让出CPU时间

5. 硬件中断

#### 1.2.4:如何减少上下文切换

1:无锁并发编程

尽量的避免使用锁，比如数据的id按照hash算法取模分段，不同线程处理不同段的数据。感觉很熟悉是吧。

2:CAS算法：Java的Atomic包使用了CAS算法来更新数据，不需要加锁。

3:使用最小线程

避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，那么很多线程都处于等待状态。

4:协程 

在单线程里面实现多个任务的调度，并在单线程里面实现多个任务间的切换。

1.2.5 减少上下文切换的实战

根据实际情况决定线程池的线程个数，避免大多线程处于等待状态

1.3:死锁

1.3.1:如何避免死锁。

注意发生死锁的一个概念。发生死锁的一个条件是什么。利用此即可。

1.避免一个条件线程线程同时获取多个锁。

2.避免一个线程在锁内同时获取多个资源，尽量保证每个锁只占用一个资源。

3.尝试使用定时锁，使用lock.tryLock()来替代内部锁机制。

4.对于数据库锁，加锁解锁必须在一个数据库连接池里面。不然解锁会失败。

#### 1.4:资源限制

受限于硬件以及计算机资源，很多情况下并不是并发就一定是最好的选择。上下文切换，资源调度都是需要考虑的问题。

在并行和串行中找到适合业务的才是最好的。

如果在资源受限的情况下想要达成并行的效果可以考虑数据分类分片。
举个很简单的例子，你的资源是10M，你的带宽只有一秒1M，那么可以考虑资源切割分片，并行处理。这个例子太糙类。

### 局外话：

r 表示运行队列(就是说多少个进程真的分配到CPU)

     当这个值超过了CPU数目，就会出现CPU瓶颈了。这个也和top的负载有关系，一般负载超过了3就比较高，超过了5就高，超过了10就不正常了，服务器的状态很危险。top的负载类似每秒的运行队列。如果运行队列过大，表示你的CPU很繁忙，一般会造成CPU使用率很高。
   
b 表示阻塞的进程,这个不多说，进程阻塞，大家懂的。

swpd 虚拟内存已使用的大小

    如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。
free 

    空闲的物理内存的大小
    
buff 设备和设备之间的缓冲 
     
    Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存
     
cache  cpu和内存之间的缓冲
    
    cache直接用来记忆我们打开的文件,给文件做缓冲，我本机大概占用300多M(这     里是Linux/Unix的聪明之处，把空闲的物理内存的一部分拿来做文件和目录的缓存，是为了提高 程序执行的性能，当程序使用内存时，buffer/cached会很快地被使用。)
    
si  

    每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。我的机器内存充裕，一切正常。
so  

    每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上。 
    bi  块设备每秒接收的块数量，这里的块设备是指系统上所有的磁盘和其他块设备，默认块大小是1024byte
   
   
bo 

    块设备每秒发送的块数量，例如我们读取文件，bo就要大于0。bi和bo一般都要接近0，不然就是IO过于频繁，需要调整。
in 每秒CPU的中断次数，包括时间中断
cs 每秒上下文切换次数
    
        例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。
us 用户CPU时间
    
    (机器在做压力测试，性能表现不佳)。
sy 
    
    系统CPU时间，如果太高，表示系统调用时间长，例如是IO操作频繁。
id  

    空闲 CPU时间，一般来说，id + us + sy = 100,一般我认为id是空闲CPU使用率，us是用户CPU使用率，sy是系统CPU使用率。
wa 等待IO CPU时间。



#### IO/CPU/men连锁反应
    1.free急剧下降
    2.buff和cache被回收下降，但也无济于事
    3.依旧需要使用大量swap交换分区swpd
    4.等待进程数，b增多
    5.读写IO，bi bo增多
    6.si so大于0开始从硬盘中读取
    7.cpu等待时间用于 IO等待，wa增加
内存不足

    1.开始使用swpd，swpd不为0
    2.si so大于0开始从硬盘中读取
io瓶颈：

    1.读写IO，bi bo增多超过2000
    2.cpu等待时间用于 IO等待，wa增加 超过20
    3.sy 系统调用时间长，IO操作频繁会导致增加 >30%
    4.wa io等待时间长
        iowait% <20%            良好
        iowait% <35%            一般
        iowait% >50%
    5.进一步使用iostat观察
CPU瓶颈：load,vmstat中r列

    1.反应为CPU队列长度
    2.一段时间内，CPU正在处理和等待CPU处理的进程数之和，直接反应了CPU的使用和申请情况。
    3.理想的load average：核数*CPU数*0.7
        CPU个数：grep 'physical id' /proc/cpuinfo | sort -u
        核数：grep 'core id' /proc/cpuinfo | sort -u | wc -l
    4.超过这个值就说明已经是CPU瓶颈了
CPU瓶颈

    1.us 用户CPU时间高超过90%
    涉及到web服务器，cs 每秒上下文切换次数
    例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目,例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。
    1.cs可以对apache和nginx线程和进程数限制起到一定的参考作用
    2.我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了
较好的趋势：主要是 swap使用少，swpd数值低。si so分页读取写入数值趋近于零


